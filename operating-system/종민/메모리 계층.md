## 1. 메모리 계층 (Memory Hierarchy)

메모리 계층은 컴퓨터 시스템에서 데이터를 저장하는 다양한 저장 장치의 구조를 의미하며, 속도와 비용, 용량에 따라 계층화된다.

### 메모리 계층 구조

1. **레지스터 (Register)**: CPU 내부의 가장 빠른 저장 공간, 용량이 작고 속도가 가장 빠름.
2. **캐시 메모리 (Cache Memory)**: CPU와 주기억장치(RAM) 사이의 중간 단계 역할. 속도가 빠르지만 용량이 작음.
3. **주기억장치 (Main Memory, RAM)**: 실행 중인 프로그램이 사용하는 기본 메모리, 속도는 캐시보다 느리고 저장 용량이 큼.
4. **보조기억장치 (Secondary Storage, HDD/SSD)**: 데이터를 영구적으로 저장하는 저장 장치, 속도가 느리지만 용량이 큼.
5. **가상메모리 (Virtual Memory)**: RAM이 부족할 경우, HDD나 SSD의 일부를 메모리처럼 사용.

메모리 계층 구조는 **속도가 빠를수록 용량이 작고 비싸며, 느릴수록 용량이 크고 저렴한 특징**을 가진다.

---

## 2. 가상메모리, 스와핑, 페이지 폴트, 스레싱

### 2.1 가상 메모리 (Virtual Memory)

- 실제 RAM 크기를 초과하는 프로그램을 실행할 수 있도록 디스크 공간을 메모리처럼 사용하는 기법.
- 운영체제는 필요한 데이터만 메모리에 올리고 나머지는 디스크에 저장해둠.
- CPU가 프로그램을 실행할 때, 필요한 데이터가 메모리에 없으면 디스크에서 불러옴.

### 2.2 스와핑 (Swapping)

- 실행 중인 프로세스 전체를 디스크로 이동시키고, 다시 필요할 때 메모리로 불러오는 기법.
- CPU가 다른 프로세스를 실행하기 위해 기존 프로세스를 디스크로 내리고 새로운 프로세스를 메모리에 올림.
- **단점**: 디스크 I/O가 많아지면 성능이 크게 저하됨.

### 2.3 페이지 폴트 (Page Fault)

- 가상 메모리에서 특정 페이지가 메모리에 없을 때 발생하는 인터럽트.
- CPU가 해당 페이지를 요청하면, 운영체제가 디스크에서 해당 페이지를 로드함.
- 페이지 폴트가 너무 자주 발생하면 성능이 저하됨.

### 2.4 스레싱 (Thrashing)

- 페이지 폴트가 과도하게 발생하여 CPU가 실제 연산보다는 **페이지 교체 작업에만 대부분의 시간을 소비하는 현상**.
- **원인**: 프로세스의 메모리 요구량이 실제 물리적 메모리보다 클 때 발생.
- **해결책**: 적절한 페이지 교체 알고리즘을 사용하거나, 워킹 셋 크기 조절.

---

## 3. 페이지 히트 (Page Hit)와 페이지 미스 (Page Miss)

- **페이지 히트 (Page Hit)**: CPU가 요청한 페이지가 메모리에 존재하는 경우.
- **페이지 미스 (Page Miss)**: CPU가 요청한 페이지가 메모리에 없어서 디스크에서 가져와야 하는 경우.

페이지 미스가 많아질수록 성능이 저하되므로, 효율적인 **페이지 교체 알고리즘**을 사용하여 페이지 히트율을 높이는 것이 중요하다.

---

## 4. 페이지 교체 알고리즘

페이지 폴트 발생 시, **새로운 페이지를 메모리에 로드해야 하는데, 기존 페이지 중 어떤 것을 제거할지 결정하는 알고리즘**.

### 4.1 **오프라인 알고리즘 (LFD, Optimal Algorithm)**

- **LFD (Least Frequently Used, 최적 알고리즘)**
- 앞으로 가장 오랫동안 사용되지 않을 페이지를 교체하는 방식.
- **이론적으로 가장 효율적이지만, 미래의 페이지 사용 패턴을 예측할 수 없으므로 실제로 구현 불가능**.

### 4.2 **FIFO (First-In-First-Out)**

- 가장 먼저 메모리에 올라온 페이지를 먼저 교체하는 방식.
- 단순하지만, 오래된 페이지가 자주 사용될 경우에도 제거될 수 있어 비효율적.

### 4.3 **LRU (Least Recently Used)**

- 가장 오래 사용되지 않은 페이지를 교체하는 방식.
- **과거의 사용 패턴이 미래에도 유지된다는 가정하에 작동**.
- 캐시 관리에서도 자주 사용되는 알고리즘.

### 4.4 **NUR (Not Recently Used)**

- 페이지에 **참조 비트(Reference Bit)** 와 **수정 비트(Modified Bit)** 를 사용하여 교체할 페이지를 선택하는 방식.
- 최근 사용되지 않은 페이지를 우선적으로 교체.
- 하드웨어 지원이 필요하지만, LRU보다 구현이 단순.

### 4.5 **LFU (Least Frequently Used)**

- 사용 횟수가 가장 적은 페이지를 교체.
- **단점**: 최근에 많이 사용되었지만 이전에 적게 사용된 페이지가 제거될 수 있음.

---

## 🔥 정리

| 개념            | 설명                                                                         |
| --------------- | ---------------------------------------------------------------------------- |
| **메모리 계층** | 레지스터 → 캐시 → RAM → 가상 메모리 → 디스크 순으로 속도와 비용이 달라짐     |
| **가상 메모리** | 실제 RAM보다 큰 프로그램을 실행할 수 있도록 디스크를 활용하는 기술           |
| **스와핑**      | 프로세스 전체를 디스크로 이동시켰다가 필요할 때 다시 불러옴                  |
| **페이지 폴트** | 요청한 페이지가 메모리에 없을 때 발생하는 현상                               |
| **스레싱**      | 페이지 폴트가 과도하게 발생하여 CPU가 페이지 교체에만 시간을 소비하는 현상   |
| **페이지 히트** | 요청한 페이지가 메모리에 존재하는 경우                                       |
| **페이지 미스** | 요청한 페이지가 메모리에 없어서 디스크에서 가져와야 하는 경우                |
| **FIFO**        | 먼저 들어온 페이지를 먼저 제거하는 방식                                      |
| **LRU**         | 가장 오래 사용되지 않은 페이지를 제거                                        |
| **LFU**         | 사용 횟수가 가장 적은 페이지를 제거                                          |
| **NUR**         | 참조 비트와 수정 비트를 이용하여 최근 사용되지 않은 페이지를 제거            |
| **LFD**         | 가장 오랫동안 사용되지 않을 페이지를 교체하는 최적 알고리즘 (실제 구현 불가) |

**🔑 핵심:** 페이지 폴트를 줄이고 성능을 최적화하려면 적절한 페이지 교체 알고리즘을 선택하는 것이 중요함.
